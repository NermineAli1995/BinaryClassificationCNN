{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Image classification using Convolutional Neural Network ( CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - Building the CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11199 images belonging to 2 classes.\n",
      "Found 2800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make sure you TensorFlow and Keras installed, if you don't execute these two lines on your Anacoda command prompt or similar\n",
    "# pip install tensorflow\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Importing libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# CNN initiation\n",
    "classifier = Sequential()\n",
    "\n",
    "# Convolution layer: \n",
    "#xtracts features from a source image. Convolution helps with blurring, sharpening, edge detection, noise reduction, or other operations that can help the machine to learn specific characteristics of an image.\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "classifier.add(Dense(units = 16, activation = 'relu'))\n",
    "#We used the sigmoid activation function is the last layer of the NN because we have a classification task here of 2 classes  \n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('valid',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#To get a full vision of the all the layers and the shape of the data passed to next layer as an output\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 64, 64, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2132s 305ms/step - loss: 0.1387 - acc: 0.9426 - val_loss: 0.3604 - val_acc: 0.9140\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2101s 300ms/step - loss: 0.0368 - acc: 0.9868 - val_loss: 0.5178 - val_acc: 0.8960\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2061s 294ms/step - loss: 0.0216 - acc: 0.9926 - val_loss: 0.4510 - val_acc: 0.9036\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2125s 304ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.5449 - val_acc: 0.9161\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2612s 373ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.5195 - val_acc: 0.9147\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 4781s 683ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.5510 - val_acc: 0.9138\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 3458s 494ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.6136 - val_acc: 0.9210\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 3037s 434ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.6163 - val_acc: 0.9092\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 24534s 4s/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.6842 - val_acc: 0.9022\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2003s 286ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.4792 - val_acc: 0.9177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a993c0a58>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 7000,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"classifer.h5\") #Save your model in order to be able to reuse it without the need to run all over again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II- Testing Phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=64 #initialization of the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting our batch with test images\n",
    "batch_holder = np.zeros((5999, IMG_SIZE, IMG_SIZE, 3))\n",
    "img_dir='test/test/'\n",
    "\n",
    "for i,img in enumerate(os.listdir(img_dir)):\n",
    "    img = image.load_img(os.path.join(img_dir,img), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    batch_holder[i, :] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgNames=os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=classifier.predict_classes(batch_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[result[i][0] for i in range(0,len(result))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame({\"id\": imgNames})\n",
    "sub1['label'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='SubmissionFile.csv' target='_blank'>SubmissionFile.csv</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\ali18\\Documents\\5ds\\zindi\\cnn_medium.-master\\SubmissionFile.csv"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "sub1.to_csv(\"SubmissionFile.csv\",index=False)\n",
    "FileLink(\"SubmissionFile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
